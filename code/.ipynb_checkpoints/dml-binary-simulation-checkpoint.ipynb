{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c410edd9",
   "metadata": {},
   "source": [
    "# Simulation example\n",
    "\n",
    "In this notebook, we'll work with simulated data from the folloeing causal model:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\log\\left(\\frac{p}{1 - p}\\right) = \\theta t + g\\left(\\boldsymbol{x}\\right),\n",
    "\\end{equation*}\n",
    "where $p = Pr\\left(Y = 1 | t, \\boldsymbol{x}\\right)$ and the nuisance functions are given by\n",
    "\\begin{align*}\n",
    "  g\\left(\\boldsymbol{x}\\right) &= 10  \\sin\\left(\\pi x_1\\right) - 5  \\cos\\left(x_2\\right) + 20 x_3^2 + 10 x_4 + 5 x_5,\\\\\n",
    "  m\\left(\\boldsymbol{x}\\right)  &= 3 \\sin\\left(x_1\\right) + \\left(\\frac{1}{4}\\right)\\frac{\\exp\\left(x_2\\right)}{1 + \\exp\\left(x_2\\right)} - 2  x_3^2 + 2 x_4 + 2 x_5 = E\\left(t|\\boldsymbol{x}\\right),\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12af2a0a",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca39a128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install numpy scipy matplotlib sklearn pygam doubleml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db3010fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import logistic\n",
    "from pygam import l, s, LogisticGAM, LinearGAM\n",
    "from doubleml import DoubleMLData, DoubleMLPLR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "def gen_data(n_samples=100, n_features=5):\n",
    "    \"\"\" Generate data for the simulation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples : int\n",
    "        Number of samples to generate.\n",
    "    n_features : int\n",
    "        Number of features to generate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    z : array-like\n",
    "        Continuous outcome.\n",
    "    y : array-like\n",
    "        Binary outcome.\n",
    "    d : array-like\n",
    "        Treatment variable.\n",
    "    X : array-like\n",
    "        Matrix of covariates.\n",
    "    \"\"\"\n",
    "    X = np.random.uniform(0, 1, (n_samples, n_features))  # covariates/confounders\n",
    "    t = (3 * np.sin(X[:, 0]) + 0.25 * np.exp(X[:, 1]) / (1 + np.exp(X[:, 1])) -  # treatment variable of interest\n",
    "         2 * X[:, 2]**2 + np.dot(X[:, 3:5], np.array([2, 2])) + \n",
    "         np.random.normal(0, 1, n_samples))\n",
    "    # Generate continuous latent (i.e., unobserved) response; for more details, see\n",
    "    # https://en.wikipedia.org/wiki/Logistic_regression#As_a_latent-variable_model\n",
    "    z = (-30 + 5 * t + 10 * np.sin(np.pi * X[:, 0]) - 5 * np.cos(X[:, 1]) + \n",
    "         20 * X[:, 2]**2 + 10 * X[:, 3] + 5 * X[:, 4] + rlogit(n_samples))\n",
    "    y = (z > 0).astype(int)  # compute observed binary outcome\n",
    "    return z, y, t, X\n",
    "\n",
    "\n",
    "def rlogit(n=1, location=0, min_val=-np.inf, max_val=np.inf):\n",
    "    \"\"\" Simulate random variables from a truncated logistic distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Number of random variables to simulate.\n",
    "    location : float\n",
    "        Location parameter of the logistic distribution.\n",
    "    min_val : float\n",
    "        Lower bound of the distribution.\n",
    "    max_val : float\n",
    "        Upper bound of the distribution.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array-like\n",
    "        Simulated random variables.\n",
    "    \"\"\"\n",
    "    u = np.random.uniform(0, 1, n)\n",
    "    plogis_min = logistic.cdf(min_val, loc=location)\n",
    "    plogis_max = logistic.cdf(max_val, loc=location)\n",
    "    qlogis = logistic.ppf(u * (plogis_max - plogis_min) + plogis_min, loc=location)\n",
    "    return qlogis\n",
    "\n",
    "\n",
    "def surrogate(y, linpred):\n",
    "    \"\"\" Simulate a surrogate outcome from a fitted logit model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array-like\n",
    "        Binary outcome.\n",
    "    linpred : array-like\n",
    "        Linear predictor.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array-like\n",
    "        Simulated surrogate outcome.\n",
    "    \"\"\"\n",
    "    n = len(linpred)\n",
    "    min_v = np.full(n, -np.inf)\n",
    "    max_v = np.full(n, np.inf)\n",
    "    min_v[y > 0.5] = 0\n",
    "    max_v[y < 0.5] = 0\n",
    "    return rlogit(n, location=linpred, min_val=min_v, max_val=max_v)\n",
    "\n",
    "\n",
    "def logit(p):\n",
    "    \"\"\" Compute the logit transformation of a probability.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p : array-like\n",
    "        Probability values.\n",
    "    \"\"\"\n",
    "    p[p == 0] = 0.00000001  # to avoid division by zero\n",
    "    p[p == 1] = 0.99999999  # to avoid division by zero\n",
    "    return np.log(p / (1 - p))\n",
    "\n",
    "\n",
    "def dml_surrogate(y, trt, X):\n",
    "    \"\"\" Estimate the average treatment effect using the surrogate approach.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array-like\n",
    "        Binary outcome.\n",
    "    trt : array-like\n",
    "        Treatment variable.\n",
    "    X : array-like\n",
    "        Matrix of covariates/confounders.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Estimated average treatment effect.\n",
    "    \"\"\"\n",
    "    # Add treatment variable to the predictors/confounders\n",
    "    X_with_trt = np.column_stack((trt, X))\n",
    "    # Fit the full model using the treatment variable and confounders. Note that\n",
    "    # we force the treatment term to be linear, which is by assumption for DML\n",
    "    # with the PLR model. Additionally, based on \"domain knowledge,\" we also \n",
    "    # specify that both X4 and X4 are linear functions.\n",
    "    gam_full = LogisticGAM(l(0) + s(1) + s(2) + s(3) + l(4) + l(5)).fit(X_with_trt, y)\n",
    "    # Get the predictions on the logit scale\n",
    "    pred = logit(gam_full.predict_mu(X_with_trt))\n",
    "    # Simulate the surrogate outcome\n",
    "    sur = surrogate(y=y, linpred=pred)\n",
    "    # Proceed with double ML using the (continuous) surrogate outcome\n",
    "    gam_sur = LinearGAM(s(0) + s(1) + s(2) + l(3) + l(4)).fit(X, sur)\n",
    "    gam_trt = LinearGAM(s(0) + s(1) + s(2) + l(3) + l(4)).fit(X, trt)\n",
    "    resid_sur = gam_sur.predict(X) - sur  # denoising step\n",
    "    resid_trt = gam_trt.predict(X) - trt  # debiasing step\n",
    "    # Estimate average treatment effect (ATE) using ordinary least squares\n",
    "    ate = np.linalg.lstsq(resid_trt[:, np.newaxis], resid_sur, rcond=None)[0][0]\n",
    "    return ate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95cd798",
   "metadata": {},
   "source": [
    "# Double machine learning (DML) via the DoubleML package\n",
    "\n",
    "Some useful links:\n",
    "* [Package documentation](https://docs.doubleml.org/stable/index.html) for `DoubleML`.\n",
    "* [Original article](https://academic.oup.com/ectj/article/21/1/C1/5056401?login=false) introducing the DML procedure.\n",
    "\n",
    "According to [Lundberg et al. (2018)](https://shap.readthedocs.io/en/latest/example_notebooks/overviews/Be%20careful%20when%20interpreting%20predictive%20models%20in%20search%20of%20causal%20insights.html), DML essentially works as follows: \n",
    "1. Train a model to predict the treatment of interest (`t`) using an appropriate set of control variables (e.g., confounders). \n",
    "2. Train a model to predict the outcome (`y`) using the same set of control variables. \n",
    "3. Train a model to predict the residual variation of the outcome (the variation left after subtracting our prediction) using the residual variation of the treatment variables.\n",
    "\n",
    "**Note:** We're going to trick the DoubleML package by using a regression forest and treating the binary 0/1 outcome (`y`) as a continuous variable. This is not  normally a good idea, but a regression forest using squared error splitting with a binary outcome is exactly equivalent to a [probability forest](https://www.thieme-connect.de/products/ejournals/abstract/10.3414/ME00-01-0052), so here it just works. This way, we can illustrate the issue of using $y - p$ as a residual in the [DML algorithm assuming a partially linear regression (PLR) model](https://docs.doubleml.org/stable/guide/models.html#partially-linear-models-plm).\n",
    "\n",
    "Here, we're applying DML to both the underlying continuous (but unobserved) outcome `z` as well as the observed binary outcome `y`. In practice, we'll never observe `z` but this is to help illustrate that DML assuming a PLR model works quite well with continuous outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4995d61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.93242326] [0.18181102]\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "np.random.seed(1310)\n",
    "z, y, trt, X = gen_data(10000)\n",
    "\n",
    "# Prepare data for DoubleML\n",
    "data_z = DoubleMLData.from_arrays(x=X, y=z, d=trt)  # underlying latent outcome\n",
    "data_y = DoubleMLData.from_arrays(x=X, y=y, d=trt)  # observed binary outcome\n",
    "\n",
    "# Define learners\n",
    "learner = RandomForestRegressor(max_depth=10, n_estimators=500)\n",
    "ml_g = clone(learner)  # use a random forest to estimate g(x)\n",
    "ml_m = clone(learner)  # use a random forest to estimate m(x)\n",
    "\n",
    "# Initialize DoubleMLPLR models\n",
    "dml_plr_z = DoubleMLPLR(data_z, ml_g, ml_m, n_folds=5)\n",
    "dml_plr_y = DoubleMLPLR(data_y, ml_g, ml_m, n_folds=5)\n",
    "\n",
    "# Fit the models\n",
    "np.random.seed(7723)\n",
    "dml_plr_z.fit()\n",
    "dml_plr_y.fit()  # this will use y-p(y=1) for orthogonalization\n",
    "\n",
    "# Print coefficients\n",
    "print(dml_plr_z.coef, dml_plr_y.coef)  # [4.93242326] [0.18181102]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71950127",
   "metadata": {},
   "source": [
    "DML can even produce confidence intervals!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac06153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      2.5 %   97.5 %\n",
       " d  4.889387  4.97546,\n",
       "       2.5 %    97.5 %\n",
       " d  0.175471  0.188151)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dml_plr_z.confint(), dml_plr_y.confint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff58d372",
   "metadata": {},
   "source": [
    "Yikes, applying DML using a binary outcome comepletely missed the mark here! In [Lundberg et al. (2018)](https://shap.readthedocs.io/en/latest/example_notebooks/overviews/Be%20careful%20when%20interpreting%20predictive%20models%20in%20search%20of%20causal%20insights.html) they claim that this approach is reasonable: \n",
    "\n",
    "> We use the regression formulation of double ML, so we need to approximate the classifer as a regression model. This treats the probabilities as just quantitative value targets for least squares regression, but it turns out to be a reasonable approximation.\n",
    "\n",
    "Treating predicted probabilitities in such a way (i.e., using the discrete residuals $y - p$) is problematic for a number of reasons. In the next section, we'll show a modified DML approach based on the surrogate idea discussed in [Cheng et al. (2020)](https://www.tandfonline.com/doi/full/10.1080/10618600.2020.1775618). (**Note:** this idea is exprimental and is currently being researched by my colleages and I.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95667c5b",
   "metadata": {},
   "source": [
    "# A modified DML approach using surrogate variables\n",
    "\n",
    "The approach we take here is similar to the ordinary DML algorithm assuming a PLR model, but we first generate a continuous *surrogate variable* for use in step 1. above. This produces a more natural residual with the usual properties. For flexibility, we use [generalized additive models](https://en.wikipedia.org/wiki/Generalized_additive_model#:~:text=In%20statistics%2C%20a%20generalized%20additive,inference%20about%20these%20smooth%20functions.) (GAMs) for estimating the full model, as well as the nuisance functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6f667e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.794847013460032\n"
     ]
    }
   ],
   "source": [
    "# Check results for a single simulation\n",
    "np.random.seed(1310)\n",
    "z, y, trt, X = gen_data(10000)\n",
    "ate = dml_surrogate(y=y, trt=trt, X=X)\n",
    "print(ate)  # 4.795"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640a83b9",
   "metadata": {},
   "source": [
    "Not bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46a3fc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/links.py:149: RuntimeWarning: divide by zero encountered in divide\n",
      "  return dist.levels / (mu * (dist.levels - mu))\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/pygam.py:627: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.link.gradient(mu, self.distribution) ** 2\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/links.py:149: RuntimeWarning: divide by zero encountered in divide\n",
      "  return dist.levels / (mu * (dist.levels - mu))\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/pygam.py:627: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.link.gradient(mu, self.distribution) ** 2\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/links.py:149: RuntimeWarning: divide by zero encountered in divide\n",
      "  return dist.levels / (mu * (dist.levels - mu))\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/pygam.py:627: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.link.gradient(mu, self.distribution) ** 2\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/links.py:149: RuntimeWarning: divide by zero encountered in divide\n",
      "  return dist.levels / (mu * (dist.levels - mu))\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/pygam.py:627: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.link.gradient(mu, self.distribution) ** 2\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/links.py:149: RuntimeWarning: divide by zero encountered in divide\n",
      "  return dist.levels / (mu * (dist.levels - mu))\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/pygam.py:627: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.link.gradient(mu, self.distribution) ** 2\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/links.py:149: RuntimeWarning: divide by zero encountered in divide\n",
      "  return dist.levels / (mu * (dist.levels - mu))\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/pygam.py:627: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.link.gradient(mu, self.distribution) ** 2\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/links.py:149: RuntimeWarning: divide by zero encountered in divide\n",
      "  return dist.levels / (mu * (dist.levels - mu))\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/pygam.py:627: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.link.gradient(mu, self.distribution) ** 2\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/links.py:149: RuntimeWarning: divide by zero encountered in divide\n",
      "  return dist.levels / (mu * (dist.levels - mu))\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/pygam.py:627: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.link.gradient(mu, self.distribution) ** 2\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/links.py:149: RuntimeWarning: divide by zero encountered in divide\n",
      "  return dist.levels / (mu * (dist.levels - mu))\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/pygam.py:627: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.link.gradient(mu, self.distribution) ** 2\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/links.py:149: RuntimeWarning: divide by zero encountered in divide\n",
      "  return dist.levels / (mu * (dist.levels - mu))\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/pygam.py:627: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.link.gradient(mu, self.distribution) ** 2\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/links.py:149: RuntimeWarning: divide by zero encountered in divide\n",
      "  return dist.levels / (mu * (dist.levels - mu))\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/pygam.py:627: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.link.gradient(mu, self.distribution) ** 2\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/links.py:149: RuntimeWarning: divide by zero encountered in divide\n",
      "  return dist.levels / (mu * (dist.levels - mu))\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/pygam.py:627: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.link.gradient(mu, self.distribution) ** 2\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/links.py:149: RuntimeWarning: divide by zero encountered in divide\n",
      "  return dist.levels / (mu * (dist.levels - mu))\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/pygam.py:627: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.link.gradient(mu, self.distribution) ** 2\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/links.py:149: RuntimeWarning: divide by zero encountered in divide\n",
      "  return dist.levels / (mu * (dist.levels - mu))\n",
      "/Users/b780620/.pyenv/versions/3.8.15/lib/python3.8/site-packages/pygam/pygam.py:627: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.link.gradient(mu, self.distribution) ** 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.764729212990787\n"
     ]
    }
   ],
   "source": [
    "# Run a simple Monte Carlo simulation (this could take a while!)\n",
    "np.random.seed(1516)\n",
    "results = []\n",
    "for _ in range(100):\n",
    "    # Simulate data\n",
    "    _, y, trt, X = gen_data(10000)\n",
    "    # Estimate ATE\n",
    "    ate = dml_surrogate(y=y, trt=trt, X=X)\n",
    "    results.append(ate)\n",
    "results = np.array(results)\n",
    "print(np.mean(results))  # 4.765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93ac1ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "plt.hist(results, bins=30, edgecolor='k', alpha=0.7)\n",
    "plt.xlabel('ATE')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3646205b",
   "metadata": {},
   "source": [
    "While it doesn't seem unbiased, it certainly provides a reasonable estimate! The accuracy of this estimate also seems to increase with sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b60c775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
